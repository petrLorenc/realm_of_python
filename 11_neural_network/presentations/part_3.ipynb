{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c21b0413c322e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T09:07:55.824360Z",
     "start_time": "2025-07-01T09:07:55.001586Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74afa0a74ddfa2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T09:07:56.088122Z",
     "start_time": "2025-07-01T09:07:55.974756Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MLP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      5\u001b[39m train_x = [\n\u001b[32m      6\u001b[39m     [\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m],\n\u001b[32m      7\u001b[39m     [\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m],\n\u001b[32m      8\u001b[39m     [\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m],\n\u001b[32m      9\u001b[39m     [\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m]\n\u001b[32m     10\u001b[39m ]\n\u001b[32m     12\u001b[39m train_y = [\n\u001b[32m     13\u001b[39m     [\u001b[32m0\u001b[39m],\n\u001b[32m     14\u001b[39m     [\u001b[32m1\u001b[39m],\n\u001b[32m     15\u001b[39m     [\u001b[32m1\u001b[39m],\n\u001b[32m     16\u001b[39m     [\u001b[32m0\u001b[39m]\n\u001b[32m     17\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m mlp = \u001b[43mMLP\u001b[49m(n_in=\u001b[32m2\u001b[39m, internal_dims=[\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m])\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(mlp.forward(train_x[\u001b[32m0\u001b[39m]))\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(mlp.forward(train_x[\u001b[32m1\u001b[39m]))\n",
      "\u001b[31mNameError\u001b[39m: name 'MLP' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "train_x = [\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "]\n",
    "\n",
    "train_y = [\n",
    "    [0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0]\n",
    "]\n",
    "\n",
    "mlp = MLP(n_in=2, internal_dims=[2, 1])\n",
    "\n",
    "print(mlp.forward(train_x[0]))\n",
    "print(mlp.forward(train_x[1]))\n",
    "print(mlp.forward(train_x[2]))\n",
    "print(mlp.forward(train_x[3]))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c7533ba84a5c40",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10_000\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmlp\u001b[49m.zero_grad()  \u001b[38;5;66;03m# Reset gradients before each epoch\u001b[39;00m\n\u001b[32m      4\u001b[39m     overall_loss = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_x)):\n",
      "\u001b[31mNameError\u001b[39m: name 'mlp' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(10_000):\n",
    "    mlp.zero_grad()  # Reset gradients before each epoch\n",
    "    \n",
    "    overall_loss = None\n",
    "    for i in range(len(train_x)):\n",
    "        inputs = train_x[i]\n",
    "        target = train_y[i]\n",
    "\n",
    "        outputs = mlp(inputs)  # Forward pass\n",
    "        if overall_loss is None:\n",
    "            overall_loss = (outputs - target[0]) ** 2  # Mean Squared Error\n",
    "        else:\n",
    "            overall_loss += (outputs - target[0]) ** 2  # Mean Squared Error - Accumulate loss\n",
    "\n",
    "    overall_loss.backward()  # Backward pass to compute gradients\n",
    "\n",
    "    # Update parameters using gradient descent\n",
    "    learning_rate = 0.1\n",
    "    for param in mlp.parameters():\n",
    "        param.data -= learning_rate * param.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a53900e297f70da5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmlp\u001b[49m.forward(train_x[\u001b[32m0\u001b[39m]))\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(mlp.forward(train_x[\u001b[32m1\u001b[39m]))\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(mlp.forward(train_x[\u001b[32m2\u001b[39m]))\n",
      "\u001b[31mNameError\u001b[39m: name 'mlp' is not defined"
     ]
    }
   ],
   "source": [
    "print(mlp.forward(train_x[0]))\n",
    "print(mlp.forward(train_x[1]))\n",
    "print(mlp.forward(train_x[2]))\n",
    "print(mlp.forward(train_x[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e5e89e771f5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to do the MLP\n",
    "# A MLP is a array of \"layers\"\n",
    "# A Layer is a array of \"neurons\"\n",
    "# A Neuron is a set of \"weights\" and a \"bias\"\n",
    "    # !! A Neuron is mathematical function that takes inputs and produces an output !!\n",
    "    # It is differentiable, so we can compute the gradient of the output with respect to the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40da7d06b381222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for 2d input: f(x) = sigmoid(weight[0] * input[0] + weight[1] * input[1] + bias)\n",
    "\n",
    "# NEURON\n",
    "1.00 (sigmoid, grad:1.0000, id:4661414864, name='')                     # activation_function(weight[0] * input[0] + weight[1] * input[1] + bias)\n",
    "    └── 17.00 (+, grad:0.0000, id:4661412048, name='')                  # weight[0] * input[0] + weight[1] * input[1] + bias\n",
    "        ├── 3.00 (leaf, grad:0.0000, id:4661425360, name='')            # bias\n",
    "        └── 14.00 (+, grad:0.0000, id:4661420496, name='')              # weight[0] * input[0] + weight[1] * input[1]\n",
    "            ├── 10.00 (*, grad:0.0000, id:4661413200, name='')          # weight[0] * input[0]\n",
    "            │   ├── 5.00 (leaf, grad:0.0000, id:4661417168, name='')    # weight[0]\n",
    "            │   └── 2.00 (leaf, grad:0.0000, id:4661413072, name='')    # input[0]\n",
    "            └── 4.00 (*, grad:0.0000, id:4661421904, name='')           # weight[1] * input[1]\n",
    "                ├── 4.00 (leaf, grad:0.0000, id:4661413456, name='')    # weight[1]\n",
    "                └── 1.00 (leaf, grad:0.0000, id:4661412432, name='')    # input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a20f3ffea97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for 2d input: f(x)[0] = sigmoid(weight[0][0] * input[0] + weight[0][1] * input[1] + bias[0])\n",
    "#                        f(x)[1] = sigmoid(weight[1][1] * input[0] + weight[1][1] * input[1] + bias[1])\n",
    "\n",
    "# LAYER - multiple NEURONS\n",
    "    ├── 0.18 (sigmoid, grad:0.0000, id:4677799888, name='')                 # output of NEURON 1\n",
    "    │   └── -1.50 (+, grad:0.0000, id:4677800016, name='')\n",
    "    │       ├── -0.47 (leaf, grad:0.0000, id:4677804624, name='')\n",
    "    │       └── -1.03 (+, grad:0.0000, id:4677800528, name='')\n",
    "    │           ├── 0.49 (*, grad:0.0000, id:4677801040, name='')\n",
    "    │           │   ├── 4.00 (leaf, grad:0.0000, id:4677801680, name='')\n",
    "    │           │   └── 0.12 (leaf, grad:0.0000, id:4677804752, name='')\n",
    "    │           └── -1.52 (*, grad:0.0000, id:4677802192, name='')\n",
    "    │               ├── -0.51 (leaf, grad:0.0000, id:4677804880, name='')\n",
    "    │               └── 3.00 (leaf, grad:0.0000, id:4677802448, name='')\n",
    "    └── 0.84 (sigmoid, grad:0.0000, id:4677802704, name='')                 # output of NEURON 2\n",
    "        └── 1.69 (+, grad:0.0000, id:4677802960, name='')\n",
    "            ├── -0.47 (leaf, grad:0.0000, id:4677805008, name='')\n",
    "            └── 2.16 (+, grad:0.0000, id:4677803088, name='')\n",
    "                ├── -0.33 (*, grad:0.0000, id:4677803216, name='')\n",
    "                │   ├── 4.00 (leaf, grad:0.0000, id:4677803472, name='')\n",
    "                │   └── -0.08 (leaf, grad:0.0000, id:4677806672, name='')\n",
    "                └── 2.49 (*, grad:0.0000, id:4677803600, name='')\n",
    "                    ├── 3.00 (leaf, grad:0.0000, id:4677804496, name='')\n",
    "                    └── 0.83 (leaf, grad:0.0000, id:4677805264, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e6032cec9e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP - multiple LAYERS\n",
    "# https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=2,2,1&seed=0.76222&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\n",
    "\n",
    "# 2 -> [2, 2, 1] - 2 inputs, 2 hidden neurons in LAYER 1, 1 output neuron in LAYER 2\n",
    "\n",
    "# function for 2d input: f(x)[0][0] = sigmoid(weight[0][0][0] * input[0] + weight[0][0][1] * input[1] + bias[0][0])\n",
    "#                        f(x)[0][1] = sigmoid(weight[0][1][0] * input[0] + weight[0][1][1] * input[1] + bias[0][1])\n",
    "#                        f(x)[1][0] = sigmoid(weight[1][0][0] * f(x)[0][0] + weight[1][0][1] * f(x)[0][1] + bias[1][0])\n",
    "#                        f(x)[1][1] = sigmoid(weight[1][1][0] * f(x)[0][0] + weight[1][1][1] * f(x)[0][1] + bias[1][1])\n",
    "#                        f(x)[2][0] = sigmoid(weight[2][0][0] * f(x)[1][0] + weight[2][0][1] * f(x)[1][1] + bias[2][0])\n",
    "\n",
    "0.60 (sigmoid, grad:0.0000, id:4679856208, name='')                              # OUTPUT of NEURON 1 in LAYER 3\n",
    "    └── 0.39 (+, grad:0.0000, id:4679844816, name='')\n",
    "        ├── -0.22 (+, grad:0.0000, id:4679844944, name='')\n",
    "        │   ├── -0.54 (*, grad:0.0000, id:4679845072, name='')\n",
    "        │   │   ├── -0.99 (leaf, grad:0.0000, id:4678173136, name='')\n",
    "        │   │   └── 0.55 (sigmoid, grad:0.0000, id:4679845968, name='')                             # OUTPUT of NEURON 1 in LAYER 2\n",
    "        │   │       └── 0.20 (+, grad:0.0000, id:4679846224, name='')\n",
    "        │   │           ├── 0.02 (+, grad:0.0000, id:4679846608, name='')\n",
    "        │   │           │   ├── -0.00 (*, grad:0.0000, id:4679848016, name='')\n",
    "        │   │           │   │   ├── -0.56 (leaf, grad:0.0000, id:4678184656, name='')\n",
    "        │   │           │   │   └── 0.01 (sigmoid, grad:0.0000, id:4679850576, name='')                     # OUTPUT of NEURON 1 in LAYER 1 (same ID as bellow)\n",
    "        │   │           │   │       └── -5.06 (+, grad:0.0000, id:4679850192, name='')\n",
    "        │   │           │   │           ├── 0.01 (leaf, grad:0.0000, id:4677804368, name='')\n",
    "        │   │           │   │           └── -5.07 (+, grad:0.0000, id:4679855184, name='')\n",
    "        │   │           │   │               ├── -2.82 (*, grad:0.0000, id:4679849168, name='')\n",
    "        │   │           │   │               │   ├── 3.00 (leaf, grad:0.0000, id:4678188880, name='')\n",
    "        │   │           │   │               │   └── -0.94 (leaf, grad:0.0000, id:4677796048, name='')\n",
    "        │   │           │   │               └── -2.25 (*, grad:0.0000, id:4679850448, name='')\n",
    "        │   │           │   │                   ├── 4.00 (leaf, grad:0.0000, id:4679856080, name='')\n",
    "        │   │           │   │                   └── -0.56 (leaf, grad:0.0000, id:4677800656, name='')\n",
    "        │   │           │   └── 0.02 (*, grad:0.0000, id:4679848400, name='')\n",
    "        │   │           │       ├── 0.25 (sigmoid, grad:0.0000, id:4679851088, name='')                     # OUTPUT of NEURON 2 in LAYER 1 (same ID as bellow)\n",
    "        │   │           │       │   └── -1.11 (+, grad:0.0000, id:4679855824, name='')\n",
    "        │   │           │       │       ├── -0.95 (+, grad:0.0000, id:4679851344, name='')\n",
    "        │   │           │       │       │   ├── 2.35 (*, grad:0.0000, id:4679850704, name='')\n",
    "        │   │           │       │       │   │   ├── 3.00 (leaf, grad:0.0000, id:4678188880, name='')\n",
    "        │   │           │       │       │   │   └── 0.78 (leaf, grad:0.0000, id:4677800912, name='')\n",
    "        │   │           │       │       │   └── -3.30 (*, grad:0.0000, id:4679850832, name='')\n",
    "        │   │           │       │       │       ├── 4.00 (leaf, grad:0.0000, id:4679856080, name='')\n",
    "        │   │           │       │       │       └── -0.83 (leaf, grad:0.0000, id:4677800272, name='')\n",
    "        │   │           │       │       └── -0.16 (leaf, grad:0.0000, id:4677806416, name='')\n",
    "        │   │           │       └── 0.09 (leaf, grad:0.0000, id:4674024912, name='')\n",
    "        │   │           └── 0.18 (leaf, grad:0.0000, id:4678178896, name='')\n",
    "        │   └── 0.32 (*, grad:0.0000, id:4679845840, name='')\n",
    "        │       ├── 0.52 (sigmoid, grad:0.0000, id:4679848912, name='')                             # OUTPUT of NEURON 2 in LAYER 2\n",
    "        │       │   └── 0.06 (+, grad:0.0000, id:4679849552, name='')\n",
    "        │       │       ├── -0.24 (+, grad:0.0000, id:4679849680, name='')\n",
    "        │       │       │   ├── -0.00 (*, grad:0.0000, id:4679849808, name='')\n",
    "        │       │       │   │   ├── -0.60 (leaf, grad:0.0000, id:4674024656, name='')\n",
    "        │       │       │   │   └── 0.01 (sigmoid, grad:0.0000, id:4679850576, name='')                     # OUTPUT of NEURON 1 in LAYER 1\n",
    "        │       │       │   │       └── -5.06 (+, grad:0.0000, id:4679850192, name='')\n",
    "        │       │       │   │           ├── 0.01 (leaf, grad:0.0000, id:4677804368, name='')\n",
    "        │       │       │   │           └── -5.07 (+, grad:0.0000, id:4679855184, name='')\n",
    "        │       │       │   │               ├── -2.82 (*, grad:0.0000, id:4679849168, name='')\n",
    "        │       │       │   │               │   ├── 3.00 (leaf, grad:0.0000, id:4678188880, name='')\n",
    "        │       │       │   │               │   └── -0.94 (leaf, grad:0.0000, id:4677796048, name='')\n",
    "        │       │       │   │               └── -2.25 (*, grad:0.0000, id:4679850448, name='')\n",
    "        │       │       │   │                   ├── 4.00 (leaf, grad:0.0000, id:4679856080, name='')\n",
    "        │       │       │   │                   └── -0.56 (leaf, grad:0.0000, id:4677800656, name='')\n",
    "        │       │       │   └── -0.24 (*, grad:0.0000, id:4679850064, name='')\n",
    "        │       │       │       ├── 0.25 (sigmoid, grad:0.0000, id:4679851088, name='')                     # OUTPUT of NEURON 2 in LAYER 1\n",
    "        │       │       │       │   └── -1.11 (+, grad:0.0000, id:4679855824, name='')\n",
    "        │       │       │       │       ├── -0.95 (+, grad:0.0000, id:4679851344, name='')\n",
    "        │       │       │       │       │   ├── 2.35 (*, grad:0.0000, id:4679850704, name='')\n",
    "        │       │       │       │       │   │   ├── 3.00 (leaf, grad:0.0000, id:4678188880, name='')\n",
    "        │       │       │       │       │   │   └── 0.78 (leaf, grad:0.0000, id:4677800912, name='')\n",
    "        │       │       │       │       │   └── -3.30 (*, grad:0.0000, id:4679850832, name='')\n",
    "        │       │       │       │       │       ├── 4.00 (leaf, grad:0.0000, id:4679856080, name='')\n",
    "        │       │       │       │       │       └── -0.83 (leaf, grad:0.0000, id:4677800272, name='')\n",
    "        │       │       │       │       └── -0.16 (leaf, grad:0.0000, id:4677806416, name='')\n",
    "        │       │       │       └── -0.95 (leaf, grad:0.0000, id:4674025424, name='')\n",
    "        │       │       └── 0.30 (leaf, grad:0.0000, id:4674025680, name='')\n",
    "        │       └── 0.62 (leaf, grad:0.0000, id:4678186832, name='')\n",
    "        └── 0.61 (leaf, grad:0.0000, id:4678186960, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16220473c7f2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why it is important?\n",
    "# because you can see that Neuron, Layer and MLP are all just a set of mathematical functions with different complexities\n",
    "# important aspect is that there can be a chain on calling, as output of one layer/function is input to another layer/function\n",
    "\n",
    "# now, let's move to that from mathematical view"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
